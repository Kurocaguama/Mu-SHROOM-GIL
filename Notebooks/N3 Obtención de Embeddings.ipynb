{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9389b66f-1d4d-4e5c-b942-e1519a3d8b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f66cedb-f610-419a-86d5-fead42a8f300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_output_text</th>\n",
       "      <th>model_output_logits</th>\n",
       "      <th>model_output_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN</td>\n",
       "      <td>togethercomputer/Pythia-Chat-Base-7B</td>\n",
       "      <td>Do all arthropods have antennae?</td>\n",
       "      <td>Yes, all insects and arachnids (including spi...</td>\n",
       "      <td>[-2.57427001, 5.1865358353, 5.4173498154, 2.32...</td>\n",
       "      <td>[ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN</td>\n",
       "      <td>togethercomputer/Pythia-Chat-Base-7B</td>\n",
       "      <td>Do all arthropods have antennae?</td>\n",
       "      <td>Yes, all insects and arachnids have at least ...</td>\n",
       "      <td>[-2.57427001, 5.1865358353, 5.4173498154, 2.32...</td>\n",
       "      <td>[ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN</td>\n",
       "      <td>togethercomputer/Pythia-Chat-Base-7B</td>\n",
       "      <td>Do all arthropods have antennae?</td>\n",
       "      <td>Yes, all insects and arachnids (including spi...</td>\n",
       "      <td>[-2.57427001, 5.1865358353, 5.4173498154, 2.32...</td>\n",
       "      <td>[ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN</td>\n",
       "      <td>togethercomputer/Pythia-Chat-Base-7B</td>\n",
       "      <td>Do all arthropods have antennae?</td>\n",
       "      <td>Yes, all insects and arachnids (including spi...</td>\n",
       "      <td>[-2.57427001, 5.1865358353, 5.4173498154, 2.32...</td>\n",
       "      <td>[ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN</td>\n",
       "      <td>togethercomputer/Pythia-Chat-Base-7B</td>\n",
       "      <td>Do all arthropods have antennae?</td>\n",
       "      <td>Yes, all insects and arachnids (including spi...</td>\n",
       "      <td>[-2.57427001, 5.1865358353, 5.4173498154, 2.32...</td>\n",
       "      <td>[ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                              model_id  \\\n",
       "0   EN  togethercomputer/Pythia-Chat-Base-7B   \n",
       "1   EN  togethercomputer/Pythia-Chat-Base-7B   \n",
       "2   EN  togethercomputer/Pythia-Chat-Base-7B   \n",
       "3   EN  togethercomputer/Pythia-Chat-Base-7B   \n",
       "4   EN  togethercomputer/Pythia-Chat-Base-7B   \n",
       "\n",
       "                        model_input  \\\n",
       "0  Do all arthropods have antennae?   \n",
       "1  Do all arthropods have antennae?   \n",
       "2  Do all arthropods have antennae?   \n",
       "3  Do all arthropods have antennae?   \n",
       "4  Do all arthropods have antennae?   \n",
       "\n",
       "                                   model_output_text  \\\n",
       "0   Yes, all insects and arachnids (including spi...   \n",
       "1   Yes, all insects and arachnids have at least ...   \n",
       "2   Yes, all insects and arachnids (including spi...   \n",
       "3   Yes, all insects and arachnids (including spi...   \n",
       "4   Yes, all insects and arachnids (including spi...   \n",
       "\n",
       "                                 model_output_logits  \\\n",
       "0  [-2.57427001, 5.1865358353, 5.4173498154, 2.32...   \n",
       "1  [-2.57427001, 5.1865358353, 5.4173498154, 2.32...   \n",
       "2  [-2.57427001, 5.1865358353, 5.4173498154, 2.32...   \n",
       "3  [-2.57427001, 5.1865358353, 5.4173498154, 2.32...   \n",
       "4  [-2.57427001, 5.1865358353, 5.4173498154, 2.32...   \n",
       "\n",
       "                                 model_output_tokens  \n",
       "0  [ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...  \n",
       "1  [ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...  \n",
       "2  [ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...  \n",
       "3  [ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...  \n",
       "4  [ĠYes, ,, Ġall, Ġinsects, Ġand, Ġar, ach, n, i...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = pd.read_json(r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\train_ds\\mushroom.en-train_nolabel.v1.jsonl', lines=True) #Cambiar para directorio local\n",
    "df_en.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7497531e-7abc-4532-8856-ab225601fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>model_input</th>\n",
       "      <th>model_id</th>\n",
       "      <th>model_output_tokens</th>\n",
       "      <th>model_output_logits</th>\n",
       "      <th>model_output_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ES</td>\n",
       "      <td>¿Dónde está ubicado Cilleruelo de San Mamés?</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[C, iller, uel, o, Ġde, ĠSan, ĠMam, Ã©s, Ġes, ...</td>\n",
       "      <td>[25.4848022461, 31.8824501038, 37.6627693176, ...</td>\n",
       "      <td>Cilleruelo de San Mamés es un municipio situad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ES</td>\n",
       "      <td>¿Cuándo fue creada la comuna suiza Gampel-Brat...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[La, Ġcom, una, Ġsu, iza, Ġde, ĠG, amp, el, -,...</td>\n",
       "      <td>[20.9607429504, 21.4772224426, 31.493303299, 2...</td>\n",
       "      <td>La comuna suiza de Gampel-Bratsch fue creada e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ES</td>\n",
       "      <td>¿Cuál es el único continente en el que habitan...</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[La, Ġrespuesta, Ġes, ĠAustralia, ., ĠLos, Ġco...</td>\n",
       "      <td>[20.0091133118, 20.0120868683, 23.2712993622, ...</td>\n",
       "      <td>La respuesta es Australia. Los corvinos negros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ES</td>\n",
       "      <td>¿Qué significa la abreviatura IOMMU?</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[I, OM, MU, Ġes, Ġla, Ġab, rev, i, atura, Ġde,...</td>\n",
       "      <td>[27.5002536774, 26.0147819519, 33.4270744324, ...</td>\n",
       "      <td>IOMMU es la abreviatura de \"Input/Output Memor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ES</td>\n",
       "      <td>¿Quién ganó la Copa de Clubes de Asia 1997-98?</td>\n",
       "      <td>meta-llama/Meta-Llama-3-8B-Instruct</td>\n",
       "      <td>[La, ĠCopa, Ġde, ĠClub, es, Ġde, ĠAsia, Ġ, 199...</td>\n",
       "      <td>[23.1833496094, 19.6576976776, 23.4080142975, ...</td>\n",
       "      <td>La Copa de Clubes de Asia 1997-98 fue ganada p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang                                        model_input  \\\n",
       "0   ES       ¿Dónde está ubicado Cilleruelo de San Mamés?   \n",
       "1   ES  ¿Cuándo fue creada la comuna suiza Gampel-Brat...   \n",
       "2   ES  ¿Cuál es el único continente en el que habitan...   \n",
       "3   ES               ¿Qué significa la abreviatura IOMMU?   \n",
       "4   ES     ¿Quién ganó la Copa de Clubes de Asia 1997-98?   \n",
       "\n",
       "                              model_id  \\\n",
       "0  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "1  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "2  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "3  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "4  meta-llama/Meta-Llama-3-8B-Instruct   \n",
       "\n",
       "                                 model_output_tokens  \\\n",
       "0  [C, iller, uel, o, Ġde, ĠSan, ĠMam, Ã©s, Ġes, ...   \n",
       "1  [La, Ġcom, una, Ġsu, iza, Ġde, ĠG, amp, el, -,...   \n",
       "2  [La, Ġrespuesta, Ġes, ĠAustralia, ., ĠLos, Ġco...   \n",
       "3  [I, OM, MU, Ġes, Ġla, Ġab, rev, i, atura, Ġde,...   \n",
       "4  [La, ĠCopa, Ġde, ĠClub, es, Ġde, ĠAsia, Ġ, 199...   \n",
       "\n",
       "                                 model_output_logits  \\\n",
       "0  [25.4848022461, 31.8824501038, 37.6627693176, ...   \n",
       "1  [20.9607429504, 21.4772224426, 31.493303299, 2...   \n",
       "2  [20.0091133118, 20.0120868683, 23.2712993622, ...   \n",
       "3  [27.5002536774, 26.0147819519, 33.4270744324, ...   \n",
       "4  [23.1833496094, 19.6576976776, 23.4080142975, ...   \n",
       "\n",
       "                                   model_output_text  \n",
       "0  Cilleruelo de San Mamés es un municipio situad...  \n",
       "1  La comuna suiza de Gampel-Bratsch fue creada e...  \n",
       "2  La respuesta es Australia. Los corvinos negros...  \n",
       "3  IOMMU es la abreviatura de \"Input/Output Memor...  \n",
       "4  La Copa de Clubes de Asia 1997-98 fue ganada p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es = pd.read_json(r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\train_ds\\mushroom.es-train_nolabel.v1.jsonl', lines=True)\n",
    "df_es.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b30d476-00fa-4989-ac2c-160876f31fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES\n",
    "\n",
    "def noun_list(a, lang):\n",
    "    \"\"\"\n",
    "    Filtra la pregunta y obtiene las PoST relevantes.\n",
    "    \n",
    "    a = list; Lista de preguntas del dataset\n",
    "    lang = 'es' or 'en'; Idioma a trabajar\n",
    "    \"\"\"\n",
    "    if lang == 'es':\n",
    "        post_spacy = spacy.load(\"es_core_news_sm\")\n",
    "    else:\n",
    "        post_spacy = spacy.load(\"en_core_web_sm\")\n",
    "    noun_list = []\n",
    "    nums = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "    for _ in a:\n",
    "        doc = post_spacy(_)\n",
    "        sub_noun = []\n",
    "        for token in doc:\n",
    "            if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\" or token.pos_ == \"NUM\":\n",
    "                sub_noun.append(token.text)\n",
    "            if token.pos_ == \"ADJ\" and token.text[0] in nums:\n",
    "                sub_noun.append(token.text)\n",
    "        noun_list.append(sub_noun)\n",
    "    return noun_list\n",
    "\n",
    "def keyword_por_preg(n_list):\n",
    "    \"\"\"\n",
    "    Junta lista de PoST previo a pasarlo por el API de Wikipedia.\n",
    "    \n",
    "    n_list = list; Obtenida de la función noun_list().\n",
    "    \"\"\"\n",
    "    keyword_list = []\n",
    "    for i in n_list:\n",
    "        keyword = ''\n",
    "        for j in i:\n",
    "            keyword = keyword + j + ' '\n",
    "        keyword_list.append(keyword)\n",
    "    return keyword_list\n",
    "\n",
    "# Esta función regresa el título de la página de wikipedia más relevante.\n",
    "# text = str ; El texto proveniente de keyword_list.\n",
    "def get_wikipage(text, lang, page_total):\n",
    "    \"\"\"\n",
    "    Regresa las n páginas de Wikipedia más relevantes al query\n",
    "\n",
    "    text = str; Texto proveniente de la función keyword_por_preg()\n",
    "    lang = 'es' or 'en'; Lenguaje necesario para wikipedia\n",
    "    page_total = int; Cantidad de páginas a regresar\n",
    "    \"\"\"\n",
    "    if lang == 'es':\n",
    "        wikipedia.set_lang('es')\n",
    "    if lang == 'en':\n",
    "        wikipedia.set_lang('en')\n",
    "    page_title = wikipedia.search(text, results = page_total)\n",
    "    return page_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01bc931d-00e4-42c3-97e9-2a5633ee982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pandas column; Correspondiente a la columna de \"model_input\" del dataset en cuestión\n",
    "# lang = str; Correspondiente al idioma enfocado\n",
    "\n",
    "# Nos regresa la lista de resúmenes correspondientes a cada \"model_input\".\n",
    "\n",
    "# Se puede optimizar verificando que el valor previo de la lista noun_list_perrona es el mismo que el actual.\n",
    "# Perdón por poner hacer este algoritmo cuadrático. ¿Quién me va a castigar? ¿Dios? ¿Karla? ¿Diego? No creo, así que en realidad puedo hacer lo que yo quiera.\n",
    "\n",
    "def wikipipeline(dataset, lang, page_count):\n",
    "    \"\"\"\n",
    "    Genera los resúmenes que sirven como contexto de cada pregunta. \n",
    "\n",
    "    dataset = pd.DataFrame ; El nombre del dataset a procesar\n",
    "    dataset = list; ya sea el nombre del dataset en formato dataset[\"model_input\"] o list(set(dataset[\"model_input\"]))\n",
    "    lang = 'es' or 'en'; Idioma a trabajar, debe de coincidir con el del dataset para no generar algo incoherente\n",
    "    page_count = int; Cantidad de páginas de Wikipedia a extraer\n",
    "    \"\"\"\n",
    "    \n",
    "    #input_column = dataset[\"model_input\"]\n",
    "    noun_list_perrona = noun_list(dataset, lang)\n",
    "    key_list = keyword_por_preg(noun_list_perrona)\n",
    "\n",
    "    resumen_list = []\n",
    "    question_list = []\n",
    "    iterador = 0\n",
    "    for i in key_list:\n",
    "        pages = get_wikipage(i, lang, page_count)\n",
    "        resumen = ''\n",
    "        for x in pages:\n",
    "            try:\n",
    "                page = wikipedia.WikipediaPage(x)\n",
    "            except wikipedia.exceptions.DisambiguationError: # Se usa para evitar problemas al encontrar la página adecuada.\n",
    "                print(i, page)\n",
    "            page_sum = page.summary\n",
    "            resumen = resumen + '' + page_sum\n",
    "        resumen_list.append(resumen)\n",
    "        question_list.append(dataset[iterador]) # Estos son las palabras claves de cada pregunta, no la pregunta misma.\n",
    "        iterador += 1\n",
    "    return resumen_list, question_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca2a426-bc87-43c7-94e5-cc55e1d71ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name Edu Manga  <WikipediaPage 'List of active Swedish Navy ships'>\n",
      "oriole  <WikipediaPage 'Eoin Morgan'>\n",
      "estación  <WikipediaPage 'Twarde Pierniki Toruń'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Apéndice (artrópodos)'>\n",
      "CPU times: total: 5.61 s\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cjto_en = list(set(df_en[\"model_input\"]))\n",
    "cjto_es = list(set(df_es[\"model_input\"]))\n",
    "sum_set_en, q_set_en = wikipipeline(cjto_en, 'en', 2)\n",
    "sum_set_es, q_set_es = wikipipeline(cjto_es, 'es', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "690644ff-6670-45e1-872b-a0f771a8ea33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name Edu Manga  <WikipediaPage 'Municipalities of the canton of Fribourg'>\n",
      "oriole  <WikipediaPage 'Index of Florida-related articles'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "name Edu Manga  <WikipediaPage 'Municipalities of the canton of Fribourg'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "name Edu Manga  <WikipediaPage 'Edu Manga'>\n",
      "oriole  <WikipediaPage 'Index of Florida-related articles'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Baltimore oriole'>\n",
      "oriole  <WikipediaPage 'Löwenhielm family'>\n",
      "name Edu Manga  <WikipediaPage 'Ole Einar Bjørndalen'>\n",
      "oriole  <WikipediaPage 'Löwenhielm family'>\n",
      "name Edu Manga  <WikipediaPage 'Ole Einar Bjørndalen'>\n",
      "oriole  <WikipediaPage 'Löwenhielm family'>\n",
      "name Edu Manga  <WikipediaPage 'Ole Einar Bjørndalen'>\n",
      "oriole  <WikipediaPage 'Löwenhielm family'>\n",
      "name Edu Manga  <WikipediaPage 'Ole Einar Bjørndalen'>\n",
      "estación  <WikipediaPage 'Junta de Galicia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Junta de Galicia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Junta de Galicia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Junta de Galicia'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "país ciudad Lugdunum  <WikipediaPage 'Brasil'>\n",
      "estación  <WikipediaPage 'Carlos IX de Suecia'>\n",
      "CPU times: total: 58.2 s\n",
      "Wall time: 26min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "summary_eng, q_en = wikipipeline(df_en[\"model_input\"], 'en', 2)\n",
    "summary_es, q_es = wikipipeline(df_es[\"model_input\"], 'es', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a4138a-8324-4bcb-a2d0-3ef933e7c6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f0c698f395431f8c1f5a53e83bf9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16 = True)\n",
    "\n",
    "def generate_embeddings(sum_list, q, ruta):\n",
    "    \"\"\"\n",
    "    Genera dataframe de embeddings, y los guarda en un directorio de nuestra elección.\n",
    "\n",
    "    sum_list = list ; Lista de resúmenes obtenida previamente.\n",
    "    q = list ; Lista de preguntas obtenida previamente.\n",
    "    ruta = str ; Directorio para guardar. \n",
    "    \"\"\"\n",
    "    len_list = [len(_) for _ in sum_list]\n",
    "    max_length = max(len_list)\n",
    "\n",
    "    embs = model.encode(\n",
    "        sum_list,\n",
    "        batch_size = 12,\n",
    "        max_length = max_length,\n",
    "    )['dense_vecs']\n",
    "\n",
    "    embs_loco = [_ for _ in embs]\n",
    "    dic = {'Embedding':embs_loco, 'Texto':sum_list, 'Keywords Pregunta': q}\n",
    "    embs_df = pd.DataFrame(data=dic)\n",
    "    #embs_df = embs_df.rename(columns={0:\"Embedding\"})\n",
    "    embs_df.to_csv(ruta)\n",
    "    print(f\"Embedding guardados en la ruta {ruta} . Saludos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98733f61-5778-4630-9b73-0fb79f4e27e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 68/68 [00:00<00:00, 242.75it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "Inference Embeddings: 100%|██████████| 68/68 [00:16<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding guardados en la ruta C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\eng_embs.csv . Saludos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|██████████| 41/41 [00:00<00:00, 242.91it/s]\n",
      "Inference Embeddings: 100%|██████████| 41/41 [00:12<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding guardados en la ruta C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\es_embs.csv . Saludos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_embeddings(summary_eng, q_en, r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\eng_embs.csv')\n",
    "generate_embeddings(summary_es, q_es, r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\es_embs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27f1548-cba3-4abb-905c-e3792e652a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding guardados en la ruta C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\eng_embs_singulares.csv . Saludos\n",
      "Embedding guardados en la ruta C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\es_embs_singulares.csv . Saludos\n"
     ]
    }
   ],
   "source": [
    "generate_embeddings(sum_set_en, q_set_en, r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\eng_embs_singulares.csv')\n",
    "generate_embeddings(sum_set_es, q_set_es, r'C:\\Users\\FLopezP\\Documents\\GitHub\\Mu-SHROOM-GIL\\Datasets\\embeddings\\es_embs_singulares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12b398-b551-4fea-a132-1ac3d5d1ece3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
